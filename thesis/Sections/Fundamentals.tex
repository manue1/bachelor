\chapter{Fundamentals and related work}

\section{Software-Defined Networking}

The origin of Software-Defined Networking (SDN) began already in 1995, however the first use cases were only developed in 2001 and the promotion of SDN only began with the foundation of the non-profit industry consortium Open Networking Foundation (ONF) in 2011. % % https://en.wikipedia.org/wiki/Software-defined_networking % %
The ONF is dedicated to push and adapt open standards like the OpenFlow into the industry.
In this following section a brief overview of the SDN architecture and concepts, including the OpenFlow protocol is given.

\subsection{Motivation}

Today's internet is part of the modern society, be it for private users, enterprises or vital infrastructure services. Networks are required to evolve in order to address the challenges that are entailed with new applications, services and a growing number of end-users.

With a more detailed view on the challenges of current networks one comes to see the following limitations:

% % ONF White Paper (pdf): SDN - The new norm for networks % % 
\begin{itemize}
\item \textbf{Inability to scale}: With the expansion of data centers, networks must grow too. Configuring and managing these additional network devices comes at a high administrative effort. With the virtualization of data centers network traffic patterns becomes more and more dynamic and unpredictable. With multi-tenancy a further complication is introduced, because different end-users and services need different network performance and might require traffic steering. Such scaling and network management cannot be done with a manual configuration of the underlying infrastructure.
\item \textbf{Complexity}: In the past decades new networking protocols have been adapted by the industry. To add or move any device, multiple existing switches, routes, firewalls must be touched in order to manage protocol-based mechanisms on a device-level. With the virtualization of servers the amount of interfaces that need network connectivity and the distribution of applications over a number of virtual machines (VMs) are another demand that the current fairly static networks cannot dynamically adapt to.
\item \textbf{Inconsistent policies}: For IT to apply a network- or data center-wide policy a lot of devices and mechanisms may need to be reconfigured. Virtual Machines are created and rebuilt within no time, but if for example access or security needs to be updated, the benefits of this dynamic are subverted(?).
\item \textbf{Vendor dependence}: Standards are needed to match the requirements of the markets with the capabilities of networks and enable network operators to customize the network to specific environments.
\end{itemize}

Traditionally decisions about traffic flowing through the network are made directly by each network device, because the control logic and forwarding hardware are tightly coupled.

\subsubsection{Classical switches \& routers}

Packet forwarding (data plane) and routing decisions (control plane) in classical switching and routing are both within one device. In figure .. the main components that are depicted have the following functions:
\begin{enumerate}
\item The \textbf{forwarding path} typically handles data path operations for each packet. It generally consists of Application-Specific Integrated Circuits (ASIC), network-processors or general-purpose processors that forwards frames and packets at wire speed (line-rate). Their lookup functions can be further increased with memory resources like Content Addressable Memory (CAM) or Ternary Content Addressable Memory (TCAM) to contain the forwarding information.
\item The elements in the \textbf{control plane} are based on general-purpose processors that provide services like routing and signaling protocols, including ARP, MAC Learning and forwarding tables.
\end{enumerate}

\begin{figure}[H]
\centering

\includegraphics[width=0.5\textwidth]{images/fundamentals/switch_components}

\caption{"Classical" switch components}
\end{figure}

A switch consists of multiple ports for incoming and outgoing data. Internal forwarding tables classify the packets and forward them to one or many specific ports. It does so by collecting MAC addresses and storing their corresponding port in specific tables. Layer 2 switches also support the segregation into virtual LANs (VLAN), which enables the network operator to logically isolate networks that share a single switch.

Routers forward packets on the Network layer (Layer 3) and routing-decisions are made based on IP addresses. They contain a routing table where paths to neighbour networks are stored, so that packets can be forwarded to their destination IP address. Other features that can be configured with routers are Quality of Service (QoS), Network Address Translation (NAT) and packet filtering.

The main differences between the classical architecture and SDN will be further described in the coming sections.

\subsection{Software-Defined Networking concept}

%% https://www.opennetworking.org/sdn-resources/sdn-definition % %

SDN represents a new dynamic, manageable, cost-effective and adaptable architecture that is built to serve the dynamic infrastructures that are needed as a backbone for today's data centers. Opposed to the traditional approach, network control and forwarding functions are decoupled and thus can be programmed and divided into different applications and network services.
The work of the Open Networking Foundation laid out the OpenFlow protocol as the base for modern SDN solutions.

\subsection{SDN architecture}

SDN separates the architecture into three distinct layers that communicate with each other through different APIs. In figure .. this separation is shown.

\begin{itemize}
\item \textbf{Infrastructure Layer:} here all physical and virtual devices (e.g. switches and routers) that are capable of the OpenFlow Protocol provide forwarding mechanisms on different Network Layers.
\item \textbf{Control Layer:} represents the 'network intelligence' and collects global view of the network, by communicating with the switching elements through the so called Southbound API.
\item \textbf{Application Layer:} consists of business applications that allow the network operator to extend the SDN controller on an abstracted level, without being tied to the actual details of the implementation of the infrastructure. This communication with the Control Layer


\end{itemize}

\begin{figure}[H]
\centering

\includegraphics[width=0.5\textwidth]{images/fundamentals/sdn_logical_architecture.png}

\caption{Software-Defined Network architecture}
\end{figure}

\subsection{OpenFlow}

% % https://www.opennetworking.org/sdn-resources/openflow % %

With OpenFlow the Open Networking Foundation defined the first standard communications interface between the SDN architecture's control and forwarding layers. It enables manipulation and direct access to the forwarding plane of physical as well as virtual (hypervisor-based) network devices such as switches and routers.

\begin{figure}[H]
\centering

\includegraphics[width=0.6\textwidth]{images/fundamentals/openflow_architecture.png}

\caption{OpenFlow Network Architecture}
\end{figure}

OpenFlow first of all stands for the communications protocol that is used by SDN controllers to fetch information and configure switches. Additionally it is a switch specification that defines its minimum capabilities in order to support OpenFlow.

% % Vendor OF version usage: http://www.tomsitpro.com/articles/pica8-openflow-1.4-sdn-switches,1-1927.html % %

Most of the OpenFlow-enabled switches and controllers currently still only support the OpenFlow version 1.0 (released in December 2009). The newest version at this date is 1.4, however this explanation of OpenFlow will be focussed on version 1.3 since that is the most recent specification which is supported by OpenVSwitch.
% %http://sdnhub.org/tutorials/openflow-1-3/ % %
The main features added since version 1.0 are among others support for VLANs, IPv6, tunnelling and per-flow traffic meters.

Generally the switches are backwards-compatible down to version 1.0. In the following description the focus lies on the required features of all OpenFlow capable devices, however it has to be mentioned that there is also a set of optional features.

\subsubsection{OpenFlow Controller}

The OpenFlow controller is separated from the switch and has two interfaces. The northbound interface is an API to the application layer for implementing applications that control the network. The southbound interface connects with the underlying switches using the OpenFlow protocol.

\subsubsection{OpenFlow Switch}
% %PDF: OpenFlow spec 1.3 % %

There are two varieties of OpenFlow-compliant switches:
\begin{itemize}
\item \textbf{OpenFlow-only:} in these switches all packets are processed by the OpenFlow pipeline and they have no legacy features.
\item \textbf{OpenFloy-hybrid:} support OpenFlow and normal Ethernet switching (including traditional L2 Ethernet switching, VLAN isolation, L3 routing, ACL and QoS). Most of the commercial switches that are available on the market today are this type.
\end{itemize}

An OpenFlow switch includes one ore multiple flow tables and a group table, which have the function of carrying out packet lookups and forwarding. Another component is the OpenFlow channel to the external controller.

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{images/fundamentals/openflow_switch_components.png}
\caption{OpenFlow Switch components}
\end{figure}

Through the connection using the OpenFlow protocol, it is possible for the controller to add, update and delete flow entries in flow tables.  This action can be performed either reactively or proactively. Sets of flow entries are stored in each flow table and each flow entry consists of \textit{match fields}, \textit{counters}, and a set of \textit{instructions} used for matching packets. (see OF Tables section)

The matching of flow entries begins at the first flow table, however it may continue to additional flow tables, and it uses the first matching entry from each table and performs the instruction that is linked with that specific entry. For packets without any matches a table-miss flow entry can be configured. Flow entries are usually forwarded to a physical port.

The instructions can either include actions  or modify pipeline processing. Packet forwarding, packet modification and group table processing are the possible actions. With pipeline processing packets can be permitted to be sent to other tables for further processing and metadata can be exchanged between tables.

Packets can also be directed to a group, which contains a set of actions for flooding and more complex forwarding semantics (e.g. multipath, fast reroute and link aggregation).

\subsubsection{OpenFlow Ports}
OpenFlow ports are the network interfaces used for passing packets between OpenFlow processing and the rest of the network.
There are various types of ports that are supported by OpenFlow. This section will give a short overview about this port abstraction.
Incoming OpenFlow packets enter the switch on an ingress port, are then processed by the OpenFlow pipeline and forwarded to an output port. (See OF Tables figure for processing).

There are three types of OpenFlow ports that must be supported by an OpenFlow switch:
\begin{itemize}
\item \textbf{Physical ports:} are hardware interfaces on a switch.
\item \textbf{Logical ports:} don't directly interact  with a hardware interface.
\item \textbf{Reserved ports:} contain generic forwarding actions (e.g. sending to the controller, flooding or forwarding using traditional switch processing)
\end{itemize}

\subsubsection{OpenFlow Tables}

\textbf{Pipeline Processing}

The OpenFlow pipeline defines specifies how packets correspond with each of the flow tables. 

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{images/fundamentals/openflow_pipeline_processing.png}
\caption{OpenFlow pipeline processing}
\end{figure}

As illustrated in the figure, each packet is matched against the flow entries starting at the first flow table, called flow table 0. The outcome of the match then decides if other of the sequentially numbered tables may be used. In the following sections the components of the Flow table, the matching procedures and different instructions will be described.

\textbf{Flow Table}

A flow table contains flow entries which consist of the following fields:

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline Match Fields & Priority & Counters & Instructions & Timeouts & Cookie \\ 
\hline 
\end{tabular} 
\end{center}

\begin{itemize}
\item \textbf{match fields:} ingress port, packet headers and optionally metadata
\item \textbf{priority:} set the priority of the flow entry
\item \textbf{counters:} is updated for matching packets
\item \textbf{instructions:} to alter the action set or pipeline processing
\item \textbf{timeouts:} set maximum amount of time or idle time before expiration of the flow
\item \textbf{cookie:} is a opaque data value chosen by the controller
\end{itemize}

Each flow table entry is uniquely identifiable by its match fields and priority. 

\textbf{Packet Matching}

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{images/fundamentals/openflow_packet_matching.png}
\caption{Packet flow through an OpenFlow switch}
\end{figure}



\subsubsection{OpenFlow Channel}

OpenVSwitch

\section{Cloud computing infrastructures}

\subsection{OpenStack}

\subsection{Devstack}

\subsection{OpenStack Nova}

\subsection{OpenStack Heat}

\subsection{OpenStack Neutron}


\section{Conclusion}